{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython version:       7.6.1 (need at least 1.0)\n",
      "Numpy version:        1.16.4 (need at least 1.7.1)\n",
      "SciPy version:         1.2.1 (need at least 0.12.0)\n",
      "Pandas version:       0.24.2 (need at least 0.11.0)\n",
      "Mapltolib version:     3.1.0 (need at least 1.2.1)\n",
      "Scikit-Learn version: 0.21.2 (need at least 0.13.1)\n"
     ]
    }
   ],
   "source": [
    "#IPython is what you are using now to run the notebook\n",
    "import IPython\n",
    "print( \"IPython version:      %6.6s (need at least 1.0)\" % IPython.__version__)\n",
    "\n",
    "# Numpy is a library for working with arrays and matrices\n",
    "import numpy as np\n",
    "print( \"Numpy version:        %6.6s (need at least 1.7.1)\" % np.__version__)\n",
    "\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "print( \"SciPy version:        %6.6s (need at least 0.12.0)\" % sp.__version__)\n",
    "\n",
    "# Pandas makes working with data tables easier\n",
    "import pandas as pd\n",
    "print( \"Pandas version:       %6.6s (need at least 0.11.0)\" % pd.__version__)\n",
    "\n",
    "# Module for plotting\n",
    "import matplotlib.pyplot as plt  \n",
    "from pylab import *\n",
    "print( \"Mapltolib version:    %6.6s (need at least 1.2.1)\" %\n",
    "       matplotlib.__version__)\n",
    "%matplotlib inline\n",
    "# necessary for in-line graphics\n",
    "\n",
    "# SciKit Learn implements several Machine Learning algorithms\n",
    "import sklearn\n",
    "print( \"Scikit-Learn version: %6.6s (need at least 0.13.1)\" %\n",
    "       sklearn.__version__)\n",
    "import os\n",
    "\n",
    "\n",
    "# for certain system-related functions\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Explore and prepare the data (20pt)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.1 Load the data. How many responses and variables do we have?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"wvs.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90350, 328)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 90350 rows of data, and there are 328 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.2 Create a summary table over all responses for V204: is abortion justifiable. How many non-\n",
    "missing responses (i.e. positive answers) do you find? Describe the the opinion about the abortion\n",
    "among the global pool of respondents.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    90350.000000\n",
       "mean         2.946386\n",
       "std          2.964040\n",
       "min         -5.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          5.000000\n",
       "max         10.000000\n",
       "Name: V204, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.V204.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the summary statistics for V204 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85742, 328)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['V204'] >=1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took the number of rows for which V204 > = 0.\n",
    "There are 85742 non missing (positive) responses in V204."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     40227\n",
       "5      9580\n",
       "2      7896\n",
       "3      6294\n",
       "4      4497\n",
       "6      4395\n",
       "10     4067\n",
       "7      3493\n",
       "8      3397\n",
       "9      1896\n",
       "Name: V204, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We would plot a bar graph for non missing values to view the global opinion\n",
    "\n",
    "v204_non_missing_entries = data[data['V204'] >= 1]['V204']\n",
    "v204_non_missing_entries.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(v204_non_missing_entries, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the global population, around 40000 (almost 50 %) respondents find abortion never justfiable.\n",
    "The rest of population is divided amoing their views. \n",
    "Only around 4000 respondednts find abortion always justifiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.3.a- remove everything that are not positive integers for V204 and V2 (country).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We areselecting only those rows having V024 >= 0; saving result in data1\n",
    "data1 = data[(data['V204'] >=1) & (data['V2'] >=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85742, 328)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.3.b- for all other variables, remove the missings in the sense of missing value on computer. You may\n",
    "leave negative answers in the data, otherwise I am afraid your sample size collapses.\n",
    "What is the final number of observations?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are dropping na values from all the columns; saving result in data2\n",
    "data2 = data1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 328)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final data frame, we have got 79267 rows of 328 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.4- In order to simplify the analysis below, create a new binary variable abortion as:\n",
    "abortion = 1 for V204>3; 0 otherwise***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#We add another column abortion; if V204 >1 then abortion = 1; otherwise abortion = 0\n",
    "data2['abortion'] = (data2.V204 > 3).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are dropping the V204 column as abortion column is formed from it\n",
    "del data2['V204']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 328)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.5 Compute (pearson) correlation table between abortion and all other variables in the data.\n",
    "There are many of these!\n",
    "Present these variables in descending order according to the absolute value of the correlation. It\n",
    "might look something like:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding corelation coefficients, its output is a series\n",
    "table_coef = data2[data2.columns[0:]].corr()['abortion'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V2            0.038487\n",
       "V4            0.051921\n",
       "V5           -0.028951\n",
       "V6           -0.070634\n",
       "V7            0.003503\n",
       "V8            0.075076\n",
       "V9            0.314117\n",
       "V10           0.020985\n",
       "V11           0.025678\n",
       "V12          -0.077677\n",
       "V13           0.069135\n",
       "V14          -0.039786\n",
       "V15          -0.059785\n",
       "V16          -0.012139\n",
       "V17          -0.001757\n",
       "V18          -0.057148\n",
       "V19           0.249042\n",
       "V20           0.031246\n",
       "V21           0.147118\n",
       "V22          -0.071474\n",
       "V23          -0.005926\n",
       "V24          -0.102798\n",
       "V25          -0.078377\n",
       "V26           0.095885\n",
       "V27           0.060138\n",
       "V28           0.076576\n",
       "V29           0.061569\n",
       "V30           0.026956\n",
       "V31           0.072616\n",
       "V32           0.048753\n",
       "                ...   \n",
       "V258A        -0.019390\n",
       "V265          0.042229\n",
       "Y001          0.091519\n",
       "Y002          0.049405\n",
       "MN_163A      -0.092610\n",
       "MN_163C      -0.094865\n",
       "MN_228L      -0.092581\n",
       "MN_228M      -0.094463\n",
       "MN_228N      -0.094901\n",
       "MN_228O      -0.095165\n",
       "MN_228P      -0.093948\n",
       "MN_228Q      -0.086341\n",
       "MN_228R      -0.075548\n",
       "MN_228S1     -0.091967\n",
       "MN_228S3     -0.092401\n",
       "MN_228S4     -0.092986\n",
       "MN_228S5     -0.078282\n",
       "MN_228S6     -0.092558\n",
       "MN_228S7     -0.093078\n",
       "MN_228S8     -0.092438\n",
       "MN_229A      -0.049514\n",
       "MN_230A      -0.083714\n",
       "MN_233A      -0.084056\n",
       "MN_237B1     -0.055880\n",
       "MN_249A1     -0.089339\n",
       "MN_249A3     -0.088007\n",
       "I_RELIGBEL    0.217138\n",
       "I_NORM1       0.179657\n",
       "I_VOICE1      0.090336\n",
       "abortion      1.000000\n",
       "Name: abortion, Length: 328, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the series to a dataframe\n",
    "table_coef1 = table_coef.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(table_coef1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting the index\n",
    "table_coef1.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naming the columns corectly\n",
    "table_coef1 = table_coef1.rename(columns={\"index\": \"variable\", \"abortion\": \"correlation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V2</td>\n",
       "      <td>0.038487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V4</td>\n",
       "      <td>0.051921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V5</td>\n",
       "      <td>-0.028951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V6</td>\n",
       "      <td>-0.070634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V7</td>\n",
       "      <td>0.003503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V8</td>\n",
       "      <td>0.075076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V9</td>\n",
       "      <td>0.314117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V10</td>\n",
       "      <td>0.020985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V11</td>\n",
       "      <td>0.025678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V12</td>\n",
       "      <td>-0.077677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variable  correlation\n",
       "0       V2     0.038487\n",
       "1       V4     0.051921\n",
       "2       V5    -0.028951\n",
       "3       V6    -0.070634\n",
       "4       V7     0.003503\n",
       "5       V8     0.075076\n",
       "6       V9     0.314117\n",
       "7      V10     0.020985\n",
       "8      V11     0.025678\n",
       "9      V12    -0.077677"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_coef1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are sorting according to the descending order of absolute value of correlataion column. We wuld let the poistive be positive and negative as negative\n",
    "\n",
    "table_coef2 = table_coef1.iloc[(-table_coef1['correlation'].abs()).argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>abortion</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>V205</td>\n",
       "      <td>0.548653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>V203</td>\n",
       "      <td>0.485419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>V206</td>\n",
       "      <td>0.446394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>V207</td>\n",
       "      <td>0.418271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>V152</td>\n",
       "      <td>-0.315280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V9</td>\n",
       "      <td>0.314117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>V203A</td>\n",
       "      <td>0.291576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>V146</td>\n",
       "      <td>0.272220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>V210</td>\n",
       "      <td>0.257035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variable  correlation\n",
       "327  abortion     1.000000\n",
       "228      V205     0.548653\n",
       "226      V203     0.485419\n",
       "229      V206     0.446394\n",
       "230      V207     0.418271\n",
       "165      V152    -0.315280\n",
       "6          V9     0.314117\n",
       "227     V203A     0.291576\n",
       "159      V146     0.272220\n",
       "234      V210     0.257035"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_coef2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above table we have both positive and negative values. of the absoluite value sorted in descending order. If the correlation is -1, it means perfect negavtive linear corelation. If corelation is 1, it means perfect positive linear correlation.\n",
    "If the correlation is 0, it means no linear correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "abortion has corelation 1 with itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V205, V203 and V206 have corelation around 0.5, which means they are somewhat linearly correlated with abortion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.6 convert country code V2 into dummies. First rename V2 to country. Thereafter use pd.get_dummies\n",
    "along these lines:data2 = pd.get_dummies(data, columns = ['country'])\n",
    "Afterwards, remove country variable from the data. How many rows/columns do you have now?\n",
    "How many country dummies does the data contain?\n",
    "Note that get_dummies creates a dummy for every category, so you have to remove one of these\n",
    "dummies in order to avoid perfect multicollinearity.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 328)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12,  32,  51,  36,  31,  48, 112,  76, 170, 196, 152, 156, 218,\n",
       "       233, 268, 276, 288, 344, 356, 368, 392, 400, 398, 417, 422, 434,\n",
       "       458, 484, 504, 528, 554, 566, 586, 275, 604, 608, 616, 634, 642,\n",
       "       643, 646, 702, 705, 410, 710, 724, 752, 158, 764, 780, 788, 792,\n",
       "       804, 840, 858, 860, 887, 716], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.V2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming V2 to country\n",
    "data3.rename(columns = {'V2':'country'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12,  32,  51,  36,  31,  48, 112,  76, 170, 196, 152, 156, 218,\n",
       "       233, 268, 276, 288, 344, 356, 368, 392, 400, 398, 417, 422, 434,\n",
       "       458, 484, 504, 528, 554, 566, 586, 275, 604, 608, 616, 634, 642,\n",
       "       643, 646, 702, 705, 410, 710, 724, 752, 158, 764, 780, 788, 792,\n",
       "       804, 840, 858, 860, 887, 716], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our data frame is data2. we would convert V2 into dummies and save in a dataframe data3\n",
    "data3 = pd.get_dummies(data3, columns = ['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 385)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted the country variable to dummy variables. It removed the country variable. The dataframe has 79267 rows and 386 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13',\n",
       "       ...\n",
       "       'country_752', 'country_764', 'country_780', 'country_788',\n",
       "       'country_792', 'country_804', 'country_840', 'country_858',\n",
       "       'country_860', 'country_887'],\n",
       "      dtype='object', length=385)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have to remove one of the dummy variables, so we would remove country_780\n",
    "del data3['country_780']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 384)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have removed one of the columns of country dummy variables, we have 79267 rows and 385 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Implement Cross-Validation (40pt)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q2.1- Make it as a function that takes k, the (unfitted) model, features X and the target y as\n",
    "arguments.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation3(k, unfitted_model, X, y):\n",
    "    \n",
    "    num_rows = X.shape[0] #finding the number of rows\n",
    "    \n",
    "    index_list = X.index.values.tolist() #taking a list of all the indices\n",
    "    np.random.seed(2) #setting a seed for shuffling\n",
    "    \n",
    "    np.random.shuffle(index_list) #shuffling the list of indices\n",
    "    \n",
    "    num_folds = k\n",
    "    num_elem_each_fold = int(len(index_list)/k) #find number of elements in each fold\n",
    "    folds = [list(t) for t in zip(*[iter(index_list)]*num_elem_each_fold)] #split list of indices into k folds\n",
    "    accuracy_list = [] #creating an empty list for storing model accuracy\n",
    "    f_score_list = [] #creating an empty list for storing f score\n",
    "\n",
    "    for fold in folds: #repeat for every splits\n",
    "        \n",
    "        val_indices = fold #validation indices = values \n",
    "        train_indices = np.setdiff1d(index_list, val_indices) #training indices\n",
    "        X_val = X[X.index.isin(val_indices)]\n",
    "        y_val = y[y.index.isin(val_indices)]['abortion']\n",
    "        X_train = X[X.index.isin(train_indices)]\n",
    "        y_train = y[y.index.isin(train_indices)]['abortion']\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        model = unfitted_model.fit(X_train, y_train) #fitting the model\n",
    "\n",
    "        y_pred = model.predict(X_val) #predicting the outcome on X_val\n",
    "        #y_pred1 = y_pred[:,1]\n",
    "    \n",
    "       \n",
    "\n",
    "        model_accuracy = sklearn.metrics.accuracy_score(y_val, y_pred) #measuring the accuracy on y_val and y_pred\n",
    "        model_Fscore = sklearn.metrics.f1_score(y_val, y_pred, average='macro') #measuring the F score\n",
    "\n",
    "        accuracy_list.append(model_accuracy) #adding to the list of accuracy\n",
    "        f_score_list.append(model_Fscore)\n",
    "        \n",
    "    mean_accuracy = np.mean(accuracy_list) #finding the mean of accuracy\n",
    "    mean_Fscore = np.mean(f_score_list) #finding the mean of f score\n",
    "    \n",
    "    \n",
    "    print(\"The mean accuracy and F score are as following: \")\n",
    "    return (mean_accuracy, mean_Fscore)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the best model (40)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 k-NN (13pt)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.1.1- Separate your training data into X (features), and y (target). Target will be the abortion\n",
    "variable, X are all the other features.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79267, 384)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "#selecting random sample of 5000 rows\n",
    "df_features_target = data4.sample(n = 5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the first 5000 rows of the data frame\n",
    "#df_features_target = data4.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are taking X as all the columns except abortion\n",
    "X = df_features_target.loc[:, df_features_target.columns != 'abortion']\n",
    "X.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting opnly the abortion column for y\n",
    "y = df_features_target[['abortion']]\n",
    "y.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We would normalise the X\n",
    "from sklearn import preprocessing\n",
    "X_norm = pd.DataFrame(preprocessing.normalize(X))\n",
    "\n",
    "X_norm.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.1.2- pick a k and set up the k-NN model with 10 nearest neighbours. Use your freshly-minted CV routine to cross-validate\n",
    "accuracy and F-score of your k-NN model.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We would do for 10 neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "unfitted_model = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6092, 0.4500760734976077)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = cross_validation3(5, unfitted_model, X_norm, y) #5 is for 5 fold cross validation\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.1.3- Try a few different k-NN models (pick different k, choose to normalize/not-to-normalize your\n",
    "features).***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have taken 5000 rows; and proven our function is working for running the model, we would do kNN for different number of nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nearest neighbours in KNN: 2\n",
      "The mean accuracy and F score are as following: \n",
      "(0.5944, 0.45420088151910976)\n",
      "The number of nearest neighbours in KNN: 3\n",
      "The mean accuracy and F score are as following: \n",
      "(0.5624, 0.5008931093480214)\n",
      "The number of nearest neighbours in KNN: 4\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6018000000000001, 0.46471252174689737)\n",
      "The number of nearest neighbours in KNN: 5\n",
      "The mean accuracy and F score are as following: \n",
      "(0.5771999999999999, 0.4998700264822382)\n",
      "The number of nearest neighbours in KNN: 6\n",
      "The mean accuracy and F score are as following: \n",
      "(0.611, 0.4671740866230684)\n",
      "The number of nearest neighbours in KNN: 7\n",
      "The mean accuracy and F score are as following: \n",
      "(0.5837999999999999, 0.49185207178743645)\n",
      "The number of nearest neighbours in KNN: 8\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6126, 0.4604461329648669)\n",
      "The number of nearest neighbours in KNN: 9\n",
      "The mean accuracy and F score are as following: \n",
      "(0.5882, 0.47849295567295014)\n",
      "The number of nearest neighbours in KNN: 10\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6092, 0.4500760734976077)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Let us try kNN for normalised data\n",
    "k_list = [2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for k in k_list:\n",
    "    unfitted_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    print(\"The number of nearest neighbours in KNN: {}\".format(k))\n",
    "    output = cross_validation3(5, unfitted_model, X_norm, y) #5 is for 5 fold cross validation\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed accuracy and F-score for different values of k in KNN for normalised data. We got the best result for k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nearest neighbors in kNN: 2\n",
      "The mean accuracy and F score are as following: \n",
      "(0.694, 0.6148606653531572)\n",
      "The number of nearest neighbors in kNN: 3\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6746000000000001, 0.6378831461975375)\n",
      "The number of nearest neighbors in kNN: 4\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6988000000000001, 0.6324702579596131)\n",
      "The number of nearest neighbors in kNN: 5\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6826000000000001, 0.6421137301006175)\n",
      "The number of nearest neighbors in kNN: 6\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6961999999999999, 0.6336763666304208)\n",
      "The number of nearest neighbors in kNN: 7\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6912, 0.6492768769906574)\n",
      "The number of nearest neighbors in kNN: 8\n",
      "The mean accuracy and F score are as following: \n",
      "(0.7034, 0.6451702451611647)\n",
      "The number of nearest neighbors in kNN: 9\n",
      "The mean accuracy and F score are as following: \n",
      "(0.6992, 0.6554615555992735)\n",
      "The number of nearest neighbors in kNN: 10\n",
      "The mean accuracy and F score are as following: \n",
      "(0.7043999999999999, 0.6484713923988383)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Let us try kNN for non-normalised data\n",
    "k_list = [2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for k in k_list:\n",
    "    unfitted_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    print(\"The number of nearest neighbors in kNN: {}\".format(k))\n",
    "    output = cross_validation3(5, unfitted_model, X, y) #5 is for 5 fold cross validation\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We computed accuracy and F-score for different values of k in KNN for non normalised data. We got the best result for k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.1.4- Present the results from your best k-NN model. Note: as you are using two metrics here, you\n",
    "may end up with different models performing better according to different measures.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took kNN for normalised and non normalised data for different values of k in the above codes.\n",
    "We computed accuracy and F-score for different values of k in KNN for normalised data. We got the best result for k = 9.\n",
    "We computed accuracy and F-score for different values of k in KNN for non normalised data. We got the best result for k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.2.1- Now repeat the process above with logistic regression. As we have a myriad of features anyway, we\n",
    "are not going to do any feature engineering. Just a plain logistic regression.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "unfitted_model = LogisticRegression(solver='liblinear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing logistic regression\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8252, 0.8054950075106518)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"We are doing logistic regression\")\n",
    "output = cross_validation3(10, unfitted_model, X, y) \n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.3 Now repeat the process with support vector machines while choosing between a few di\u001berent kernels and\n",
    "kernel options, such as degree for polynomial kernels.\n",
    "Hint: I have mixed experience with sklearn version of SVM. I recommend to limit the number of\n",
    "iterations, initially maybe to just 1000, in order to ensure your model actually terminates.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.3.1 pick a kernel and repeat the process above.\n",
    "Note that some kernels are slower than others, so be careful.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would initially try SVM on normalised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing SVM for linear kernel and normalised data\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.526, 0.46321582985176574)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are doing SVM on linear kernel, and normalised data\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "#The algorithm kept on running, so I have used the BaggingClassifier, n_jobs features.\n",
    "\n",
    "unfitted_model = BaggingClassifier(base_estimator=SVC(kernel='linear',max_iter=1000),n_estimators=10, random_state=0,n_jobs = -1)\n",
    "\n",
    "print(\"We are doing SVM for linear kernel and normalised data\")\n",
    "output = cross_validation3(5, unfitted_model, X_norm, y) \n",
    "\n",
    "output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing SVM for radial kernel and normalised data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6412, 0.3906425335041429)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#We are doing SVM on radial kernel and normalised data\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "#The algorithm kept on running, so I have used the BaggingClassifier, n_jobs features.\n",
    "\n",
    "unfitted_model = BaggingClassifier(base_estimator=SVC(kernel='rbf', gamma=5 ,max_iter=1000),n_estimators=10, random_state=0,n_jobs = -1)\n",
    "\n",
    "print(\"We are doing SVM for radial kernel and normalised data\")\n",
    "output = cross_validation3(5, unfitted_model, X_norm, y) \n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing SVM for polynomial kernel of degree 2 and normalised data\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5902000000000001, 0.4707015434449785)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#We would now try with polynomial kernel of degree 2 and normalised data\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#unfittedmodel = SVC(max_iter=1000)\n",
    "\n",
    "#The algorithm kept on running, so I have used the BaggingClassifier, n_jobs features.\n",
    "\n",
    "unfitted_model = clf = BaggingClassifier(base_estimator=SVC(kernel='poly', degree=2,max_iter=1000),n_estimators=10, random_state=0,n_jobs = -1)\n",
    "\n",
    "print(\"We are doing SVM for polynomial kernel of degree 2 and normalised data\")\n",
    "output = cross_validation3(5, unfitted_model, X_norm, y) \n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing SVM for polynomial kernel of degree 3 and normalised data\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5618000000000001, 0.4816606796676874)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We would now try with polynomial kernel of degree 3 and normalised data\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#unfittedmodel = SVC(max_iter=1000)\n",
    "\n",
    "#The algorithm kept on running, so I have used the BaggingClassifier, n_jobs features.\n",
    "\n",
    "unfitted_model = clf = BaggingClassifier(base_estimator=SVC(kernel='poly', degree=3,max_iter=1000),n_estimators=10, random_state=0,n_jobs = -1)\n",
    "\n",
    "print(\"We are doing SVM for polynomial kernel of degree 3 and normalised data\")\n",
    "output = cross_validation3(5, unfitted_model, X_norm, y) \n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now do SVM on non-normalised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing SVM for linear kernel and non normalised data\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5045999999999999, 0.47756928268930904)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are doing SVM on linear kernel, and non normalised data\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "#The algorithm kept on running, so I have used the BaggingClassifier, n_jobs features.\n",
    "\n",
    "unfitted_model = BaggingClassifier(base_estimator=SVC(kernel='linear',max_iter=1000),n_estimators=10, random_state=0,n_jobs = -1)\n",
    "\n",
    "print(\"We are doing SVM for linear kernel and non normalised data\")\n",
    "output = cross_validation3(5, unfitted_model, X, y) \n",
    "\n",
    "output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing SVM for radial kernel and non normalised data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6412, 0.3906425335041429)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#We are doing SVM on radial kernel and non normalised data\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "#The algorithm kept on running, so I have used the BaggingClassifier, n_jobs features.\n",
    "\n",
    "unfitted_model = BaggingClassifier(base_estimator=SVC(kernel='rbf', gamma=5 ,max_iter=1000),n_estimators=10, random_state=0,n_jobs = -1)\n",
    "\n",
    "print(\"We are doing SVM for radial kernel and non normalised data\")\n",
    "output = cross_validation3(5, unfitted_model, X, y) \n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing SVM for polynomial kernel of degree 2 and non normalised data\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.48860000000000003, 0.4431646007049433)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#We would now try with polynomial kernel of degree 2 and non normalised data\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#unfittedmodel = SVC(max_iter=1000)\n",
    "\n",
    "#The algorithm kept on running, so I have used the BaggingClassifier, n_jobs features.\n",
    "\n",
    "unfitted_model = clf = BaggingClassifier(base_estimator=SVC(kernel='poly', degree=2,max_iter=1000),n_estimators=10, random_state=0,n_jobs = -1)\n",
    "\n",
    "print(\"We are doing SVM for polynomial kernel of degree 2 and non normalised data\")\n",
    "output = cross_validation3(5, unfitted_model, X, y) \n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing SVM for polynomial kernel of degree 3 and non normalised data\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.49399999999999994, 0.4759104159096913)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We would now try with polynomial kernel of degree 3 and non normalised data\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "#unfittedmodel = SVC(max_iter=1000)\n",
    "\n",
    "#The algorithm kept on running, so I have used the BaggingClassifier, n_jobs features.\n",
    "\n",
    "unfitted_model = clf = BaggingClassifier(base_estimator=SVC(kernel='poly', degree=3,max_iter=1000),n_estimators=10, random_state=0,n_jobs = -1)\n",
    "\n",
    "print(\"We are doing SVM for polynomial kernel of degree 3 and non normalised data\")\n",
    "output = cross_validation3(5, unfitted_model, X, y) \n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.3.2 If your models worked like mine, you may have noticed that while accuracy seems all right,\n",
    "precision and recall are rather low. Explain what does such a phenomenon mean.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision = true positives /(true positives + false positives)\n",
    "\n",
    "recall = true postives/(true positives+ false negatives)\n",
    "\n",
    "F score is the weighted average of precision and recall.\n",
    "\n",
    "F score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "A low precision means that out of all the predicted positives, there is a less number of true positives.\n",
    "A low recall means that out of all the true positives, there is a less number of those correctly predicted positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.4 Compare the models (3pt)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.4.1- Finally, compare the models. Which ones performed the best in terms of accuracy? Which\n",
    "ones in terms of F-score? Did you encounter other kind of issues with certain models? Which models\n",
    "were fast and which ones slow?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model gave us the highest accurace(around 80 %) which is significantly more than the other models.\n",
    "The F-score(balanced mean of precision and recall) is also highest for logistic regression model.\n",
    "\n",
    "The KNN models with less number of nearest neighbours were slow.\n",
    "The logistic regression model was extremely fast.\n",
    "The SVM was extremely slow. My CPU usage was going to 100%, and the model terminated only after I used max_iter = 1000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.4.1 If you have to repeat the exercise with a single model (and you have, see below), which one\n",
    "will you pick?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would choose the logistic regression model because it performed best in term of accuracy and F score. It is also computationally least expensive.\n",
    "We are fitting models on human data, that is another resaon there is no particular shape to the data and defining kernels or decision boundaries wont help a lot. A linaer decision boundary model of logistic regression would do best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. How large a role does country play? (20pt)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q4.1- Pick your best ML method based you designed above. Cross-validate the accuracy of abortion\n",
    "variable using all the features, including country dummies and report the accuracy. Essentially you\n",
    "repeat here what you did above, so you can also just copy the result from above.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_features_target: our data frame having randomly selected 5000 rows\n",
    "\n",
    "X: the matrix of features(all column except y)\n",
    "\n",
    "y: the vector of target(abortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing logistic regression\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8252, 0.8054950075106518)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "unfitted_model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "print(\"We are doing logistic regression\")\n",
    "output = cross_validation3(10, unfitted_model, X, y) \n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.3.2- If your models worked like mine, you may have noticed that while accuracy seems all right,\n",
    "precision and recall are rather low. Explain what does such a phenomenon mean.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q4.2 Now remove all the country dummies, but keep the other variables intact. And repeat.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would  I would make a copy of data frame and drop all the columns starting with country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takinga copy of dataframe\n",
    "data5 = df_features_target.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12',\n",
       "       ...\n",
       "       'country_724', 'country_752', 'country_764', 'country_788',\n",
       "       'country_792', 'country_804', 'country_840', 'country_858',\n",
       "       'country_860', 'country_887'],\n",
       "      dtype='object', length=385)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 385)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the shape of data frame prior to deleting country columns\n",
    "data5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data5[data5.columns.drop(list(data5.filter(regex='country')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>MN_229A</th>\n",
       "      <th>MN_230A</th>\n",
       "      <th>MN_233A</th>\n",
       "      <th>MN_237B1</th>\n",
       "      <th>MN_249A1</th>\n",
       "      <th>MN_249A3</th>\n",
       "      <th>I_RELIGBEL</th>\n",
       "      <th>I_NORM1</th>\n",
       "      <th>I_VOICE1</th>\n",
       "      <th>abortion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26551</th>\n",
       "      <td>30666</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>12604</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>4929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5446</th>\n",
       "      <td>6130</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21749</th>\n",
       "      <td>25377</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  V4  V5  V6  V7  V8  V9  V10  V11  V12  ...  MN_229A  MN_230A  \\\n",
       "26551  30666   1   1   1   1   4   2    2    1    2  ...       -4       -4   \n",
       "11618  12604   1   3   2   4   2   2    1    3    1  ...       -4       -4   \n",
       "4268    4929   1   1   1   2   1   2    2    2    1  ...       -4       -4   \n",
       "5446    6130   1   4   2   3   3   1    3    2    2  ...        2        2   \n",
       "21749  25377   1   1   2   3   2   2    2    3    1  ...       -4       -4   \n",
       "\n",
       "       MN_233A  MN_237B1  MN_249A1  MN_249A3  I_RELIGBEL  I_NORM1  I_VOICE1  \\\n",
       "26551       -4        -4        -4        -4         1.0      1.0      0.00   \n",
       "11618       -4        -4        -4        -4         0.0      1.0      0.33   \n",
       "4268        -4        -4        -4        -4         1.0      0.0      0.00   \n",
       "5446         5         0         2         2         0.0      1.0      0.66   \n",
       "21749       -4        -4        -4        -4         1.0      1.0      1.00   \n",
       "\n",
       "       abortion  \n",
       "26551         1  \n",
       "11618         0  \n",
       "4268          0  \n",
       "5446          0  \n",
       "21749         0  \n",
       "\n",
       "[5 rows x 328 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data5['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 327)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13',\n",
       "       ...\n",
       "       'MN_229A', 'MN_230A', 'MN_233A', 'MN_237B1', 'MN_249A1', 'MN_249A3',\n",
       "       'I_RELIGBEL', 'I_NORM1', 'I_VOICE1', 'abortion'],\n",
       "      dtype='object', length=327)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have deleted the dummy country columns and the total number of columns has reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are kaing the matrix of features without abortion column\n",
    "X_without_country = data5.loc[:, data5.columns != 'abortion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are making the target y that has only the abortion column\n",
    "y_without_country = data5[['abortion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abortion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26551</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5446</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21749</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       abortion\n",
       "26551         1\n",
       "11618         0\n",
       "4268          0\n",
       "5446          0\n",
       "21749         0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_without_country.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are doing logistic regression without the country dummy variables\n",
      "The mean accuracy and F score are as following: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.819, 0.7991016620006929)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "unfitted_model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "print(\"We are doing logistic regression without the country dummy variables\")\n",
    "output = cross_validation3(10, unfitted_model, X_without_country, y_without_country) \n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q4.3- Comment what you found. Does country information help to noticeably improve the prediction?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I did logistic regression with the country dummy variables, I got the following statistics:-\n",
    "mean accuracy: 0.8252, F-score: 0.8054950075106518)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I did logistic regression without the country dummy variables, I got the following statistics:- mean accuracy: 0.819, F-score: 0.7991016620006929"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I would say that the model that had country dummy variables was not drastically better, but somewhat better that the model without country dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
