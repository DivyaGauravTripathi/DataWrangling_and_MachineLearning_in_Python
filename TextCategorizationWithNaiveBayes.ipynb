{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMT574 Problem Set 5: Naïve Bayes\n",
    "\n",
    "    \n",
    "### Introduction\n",
    "\n",
    "This problem set has two aims: a) learn to understand Naive Bayes, and b) learn to handle text, a form of data that does not come as a table of numbers. You will implement your own Naive Bayes classifier and use this for categorizing Rotten Tomatoes reviews into rotten and fresh ones. Finally, you also find the optimal smoothing parameter. Please submit a) your code (notebooks, rmd, whatever) and b) the results in a final output form (html or pdf). Note that this is groupwork, you should find 2-3 student groups (or wait until we assign you to one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotten Tomatoes\n",
    "Our first task is to load, clean and explore the Rotten Tomatoes movie reviews data. Please familiarize yourself a little bit with the webpage. Brie\u001d",
    "y, approved critics can write reviews for movies, and evaluate the movie as \u0010fresh\u0011 or \u0010rotten\u0011. The webpage normally shows a short \u0010quote\u0011 from each critic, and whether it evaluates the movie as fresh or rotten. You will work on these quotes below. The central variables for our purpose in rotten-tomatoes.csv are the following:\n",
    "fresh evaluation: 'fresh' or 'rotten'\n",
    "quote short version of the review\n",
    "There are more variables like links to IMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython version:       7.8.0 (need at least 1.0)\n",
      "Numpy version:        1.16.5 (need at least 1.7.1)\n",
      "SciPy version:         1.3.1 (need at least 0.12.0)\n",
      "Pandas version:       0.25.1 (need at least 0.11.0)\n",
      "Mapltolib version:     3.1.1 (need at least 1.2.1)\n",
      "Scikit-Learn version: 0.21.3 (need at least 0.13.1)\n"
     ]
    }
   ],
   "source": [
    "#IPython is what you are using now to run the notebook\n",
    "import IPython\n",
    "print( \"IPython version:      %6.6s (need at least 1.0)\" % IPython.__version__)\n",
    "\n",
    "# Numpy is a library for working with arrays and matrices\n",
    "import numpy as np\n",
    "print( \"Numpy version:        %6.6s (need at least 1.7.1)\" % np.__version__)\n",
    "\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "print( \"SciPy version:        %6.6s (need at least 0.12.0)\" % sp.__version__)\n",
    "\n",
    "# Pandas makes working with data tables easier\n",
    "import pandas as pd\n",
    "print( \"Pandas version:       %6.6s (need at least 0.11.0)\" % pd.__version__)\n",
    "\n",
    "# Module for plotting\n",
    "import matplotlib.pyplot as plt  \n",
    "from pylab import *\n",
    "print( \"Mapltolib version:    %6.6s (need at least 1.2.1)\" %\n",
    "       matplotlib.__version__)\n",
    "%matplotlib inline\n",
    "# necessary for in-line graphics\n",
    "\n",
    "# SciKit Learn implements several Machine Learning algorithms\n",
    "import sklearn\n",
    "print( \"Scikit-Learn version: %6.6s (need at least 0.13.1)\" %\n",
    "       sklearn.__version__)\n",
    "import os\n",
    "\n",
    "\n",
    "# for certain system-related functions\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Explore and clean the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.1 Take a look at a few lines of data (you may use pd.sample for this).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"rotten-tomatoes.csv\",sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13442, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>link</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.timeout.com/film/reviews/87745/toy-...</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.time.com/time/magazine/article/0,91...</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.newsweek.com/id/104199</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://www.variety.com/review/VE1117941294.htm...</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>http://onfilm.chicagoreader.com/movies/capsule...</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10 00:00:00</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb  \\\n",
       "0         Derek Adams  fresh  114709   \n",
       "1     Richard Corliss  fresh  114709   \n",
       "2         David Ansen  fresh  114709   \n",
       "3       Leonard Klady  fresh  114709   \n",
       "4  Jonathan Rosenbaum  fresh  114709   \n",
       "\n",
       "                                                link     publication  \\\n",
       "0  http://www.timeout.com/film/reviews/87745/toy-...        Time Out   \n",
       "1  http://www.time.com/time/magazine/article/0,91...   TIME Magazine   \n",
       "2                  http://www.newsweek.com/id/104199        Newsweek   \n",
       "3  http://www.variety.com/review/VE1117941294.htm...         Variety   \n",
       "4  http://onfilm.chicagoreader.com/movies/capsule...  Chicago Reader   \n",
       "\n",
       "                                               quote          review_date  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04 00:00:00   \n",
       "1                  The year's most inventive comedy.  2008-08-31 00:00:00   \n",
       "2  A winning animated feature that has something ...  2008-08-18 00:00:00   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09 00:00:00   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10 00:00:00   \n",
       "\n",
       "   rtid      title  \n",
       "0  9559  Toy Story  \n",
       "1  9559  Toy Story  \n",
       "2  9559  Toy Story  \n",
       "3  9559  Toy Story  \n",
       "4  9559  Toy Story  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.2 print out all variable names.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of variables is as following: \n",
      "Index(['critic', 'fresh', 'imdb', 'link', 'publication', 'quote',\n",
      "       'review_date', 'rtid', 'title'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "variables = data.columns\n",
    "print(\"The list of variables is as following: \\n{}\".format(variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fresh', 'rotten', 'none'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fresh.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.3 create a summary table (maybe more like a bullet list) where you print out the most important\n",
    "summary statistics for the most interesting variables. The most interesting facts you should present\n",
    "should include: a) number of missings for fresh and quote; b) all different values for fresh/rotten\n",
    "evaluations; c) counts or percentages of these values; d) number of zero-length or only whitespace\n",
    "quote-s; e) minimum-maximum-average length of quotes (either in words, or in characters). (Can\n",
    "you do this as an one-liner?); f) how many reviews are in data multiple times. Feel free to add more\n",
    "figures you consider relevant.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fresh     8389\n",
       "rotten    5030\n",
       "none        23\n",
       "Name: fresh, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fresh.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**There are 23 rows having none(missing value) in fresh column. There are 1833 fresh evaluations and 1260 rotten evaluations.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.quote.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 0 missing value in the quotes column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fresh.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.51583575527238"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_percent = (8389/(8389+5030))*100\n",
    "fresh_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.48416424472762"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotten_percent = (5030/(8389+5030))*100\n",
    "rotten_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.quote == ' ').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 0 number of only white spaces in quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.quote == '').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 0 number of rows having zero-length in quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121.23128998660914"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are finding the mean length of the quotes column\n",
    "mean_length = data.quote.str.len().mean()\n",
    "mean_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are finding the min length of the quotes column\n",
    "min_length = data.quote.str.len().min()\n",
    "min_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We are finding the max length of the quotes column\n",
    "max_length = data.quote.str.len().max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are making another dataframe for only those titles which are duplicate or more than one entry\n",
    "df_duplicate_title = data[data.duplicated(['title'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1555"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates=df_duplicate_title['title'].nunique() \n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1555 titles having duplicates or more than one entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.array([[\"number of rows having none (missing value) in fresh column\",23],[\"percent of fresh reviews\",fresh_percent],[\"percent of rotten reviews\",rotten_percent],\n",
    "                           [\"number of rows having missing values in quote column\",0],[\"number of titles having duplicate entries\",duplicates]]),\n",
    "                  columns = ['heading','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heading</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>number of rows having none (missing value) in ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>percent of fresh reviews</td>\n",
       "      <td>62.51583575527238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>percent of rotten reviews</td>\n",
       "      <td>37.48416424472762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>number of rows having missing values in quote ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>number of titles having duplicate entries</td>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             heading              value\n",
       "0  number of rows having none (missing value) in ...                 23\n",
       "1                           percent of fresh reviews  62.51583575527238\n",
       "2                          percent of rotten reviews  37.48416424472762\n",
       "3  number of rows having missing values in quote ...                  0\n",
       "4          number of titles having duplicate entries               1555"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q1.4-Now when you have an overview what you have in data, clean it by removing all the inconsistencies\n",
    "the table reveals. We have to ensure that the central variables, quote and fresh are not missing,\n",
    "quote is not an empty string (or just contain spaces and such), and all rows are unique.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13442, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of uncleaned data frame is 13442,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    cleaned_df = df.copy()\n",
    "    cleaned_df = cleaned_df.dropna(how = 'any', subset = ['fresh','quote']) #removing missing values from fresh and quote columns \n",
    "    cleaned_df = cleaned_df[cleaned_df['fresh'] != 'none'] #removing rows having none in the fresh column\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13419, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df = clean_data(data)\n",
    "cleaned_df.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deleted the rows having missing values in quote and fresh columns. We also deleted the rows having none in the fresh column.\n",
    "The shape of cleaned_df is 13419, 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Naïve Bayes\n",
    "\n",
    "\n",
    "**Now where you are familiar with the data, it's time to get serious and implement the Naive Bayes classifier from scratch. But first things first.**\n",
    "\n",
    "**1. Ensure you are familiar with Naive Bayes. Consult the readings, available on canvas. Schutt & O'Neill is an easy and accessible (and long) introduction, Whitten & Frank is a lot shorter but still accessible introduction. The Lecture notes contains examples how to create baf-of-words (BOW), and how to compute Naive Bayes classifier using BOW-s.**\n",
    "\n",
    "**2. Convert your data (quotes) into bag-of-words. Your code should look something like this:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#if vectorizer == None:\n",
    "vectorizer = CountVectorizer(min_df = 0,binary=True,stop_words = \"english\") \n",
    "        \n",
    "text = cleaned_df.quote.values\n",
    "vectorizer.fit(text)\n",
    "X = vectorizer.transform(text)\n",
    "feature_names = vectorizer.vocabulary_\n",
    "X = X.toarray()\n",
    "Y = cleaned_df.fresh.apply(lambda x: 1 if x == 'fresh' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000', '0014', '007', '044', '07']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13419, 20584)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13419,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would convert X(Bag of Words) to dataframe and add Y as a column to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BOW = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BOW_df = pd.DataFrame(X_BOW, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20584 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0014  007  044  07  10  100  101  104  105  ...  zoom  zooming  zooms  \\\n",
       "0    0     0    0    0   0   0    0    0    0    0  ...     0        0      0   \n",
       "1    0     0    0    0   0   0    0    0    0    0  ...     0        0      0   \n",
       "2    0     0    0    0   0   0    0    0    0    0  ...     0        0      0   \n",
       "3    0     0    0    0   0   0    0    0    0    0  ...     0        0      0   \n",
       "4    0     0    0    0   0   0    0    0    0    0  ...     0        0      0   \n",
       "\n",
       "   zorro  zorros  zowie  zucker  zweibel  zwick  zzzzzzzzz  \n",
       "0      0       0      0       0        0      0          0  \n",
       "1      0       0      0       0        0      0          0  \n",
       "2      0       0      0       0        0      0          0  \n",
       "3      0       0      0       0        0      0          0  \n",
       "4      0       0      0       0        0      0          0  \n",
       "\n",
       "[5 rows x 20584 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_BOW_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13419, 20584)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_BOW_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_BOW_df = X_BOW_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_BOW_df['Y'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    8379\n",
       "0.0    5017\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_BOW_df.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0., nan])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_BOW_df.Y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that in some of Y we have got nan, we would remove all such rows having Y as nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_BOW_df1 = XY_BOW_df.dropna(subset = ['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13396, 20585)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_BOW_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_BOW_df1.Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0014  007  044  07  10  100  101  104  105  ...  zooming  zooms  \\\n",
       "0    0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "1    0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "2    0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "3    0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "4    0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "\n",
       "   zorro  zorros  zowie  zucker  zweibel  zwick  zzzzzzzzz    Y  \n",
       "0      0       0      0       0        0      0          0  1.0  \n",
       "1      0       0      0       0        0      0          0  1.0  \n",
       "2      0       0      0       0        0      0          0  1.0  \n",
       "3      0       0      0       0        0      0          0  1.0  \n",
       "4      0       0      0       0        0      0          0  1.0  \n",
       "\n",
       "[5 rows x 20585 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XY_BOW_df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binary=True specifies that we don't want BOW-s that contains counts of words but just 1/0 for the presence/non-presence of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q2.3- Split your work data and target (i.e. the variable fresh) into training and validation chunks (80/20 or so).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(XY_BOW_df1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10716, 20585)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2680, 20585)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import train_test_split\\n# split data into training and test set \\nX_train, X_test, y_train, y_test = train_test_split(XY_df.iloc[:,:-1],XY_df.iloc[:,-1], test_size = 0.2)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split data into training and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(XY_df.iloc[:,:-1],XY_df.iloc[:,-1], test_size = 0.2)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q2.4- Compute the unconditional (log) probability that the tomato is fresh/rotten, log Pr(F), and log Pr(R).\n",
    "These probabilities are based on the values of fresh alone, not on the words the quotes contain.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finding the value counts of Y = 1 and Y = 0 in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    6715\n",
       "0.0    4001\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have denoted fresh as 1 and rotten as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1.0</td>\n",
       "      <td>6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.0</td>\n",
       "      <td>4001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y\n",
       "1.0  6715\n",
       "0.0  4001"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train.Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4001"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train.Y.value_counts())['Y'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 6667 + 4049\n",
    "Pr_fresh = 6667/total\n",
    "Pr_rotten = 4049/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Pr_fresh = np.log(Pr_fresh)\n",
    "log_Pr_rotten = np.log(Pr_rotten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4745679680464393"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log probability of fresh\n",
    "log_Pr_fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9732680146323383"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log probability of rotten\n",
    "log_Pr_rotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q2.5- For each word w, compute log Pr(w|F) and log Pr(w|R), the (log) probability that the word is present\n",
    "in a fresh/rotten review. These probabilities can easily be calculated from counts of how many times\n",
    "these words are present for each class.\n",
    "Hint: these computations are based on your BOW-s X. Look at ways to sum along columns in this\n",
    "matrix.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take our training data and subset it for Y = 1(fresh) and Y = 0(rotten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fresh = train[train['Y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rotten = train[train['Y'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6715, 20585)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fresh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       000  0014  007  044  07  10  100  101  104  105  ...  zooming  zooms  \\\n",
       "10974    0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "11364    0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "8260     0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "5968     0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "7779     0     0    0    0   0   0    0    0    0    0  ...        0      0   \n",
       "\n",
       "       zorro  zorros  zowie  zucker  zweibel  zwick  zzzzzzzzz    Y  \n",
       "10974      0       0      0       0        0      0          0  1.0  \n",
       "11364      0       0      0       0        0      0          0  1.0  \n",
       "8260       0       0      0       0        0      0          0  1.0  \n",
       "5968       0       0      0       0        0      0          0  1.0  \n",
       "7779       0       0      0       0        0      0          0  1.0  \n",
       "\n",
       "[5 rows x 20585 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fresh.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['000', '0014', '007', '044', '07', '10', '100', '101', '104', '105',\n",
       "       ...\n",
       "       'zooming', 'zooms', 'zorro', 'zorros', 'zowie', 'zucker', 'zweibel',\n",
       "       'zwick', 'zzzzzzzzz', 'Y'],\n",
       "      dtype='object', length=20585)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_fresh = train_fresh.columns\n",
    "columns_fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_fresh_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the log likelihood for word given fresh. We assign 10e-5 for all words that have count 0.\n",
    "for col in columns_fresh:\n",
    "    count = train_fresh[col].sum()\n",
    "    if count == 0:\n",
    "        words_fresh_count[col] = np.log(0.00001)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        words_fresh_count[col] = np.log(count/ train_rotten.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fresh_wordprob = pd.DataFrame(words_fresh_count, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-6.908005</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-6.684862</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-5.403928</td>\n",
       "      <td>-6.348389</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.5178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000       0014       007        044         07        10       100  \\\n",
       "0 -6.908005 -11.512925 -6.684862 -11.512925 -11.512925 -5.403928 -6.348389   \n",
       "\n",
       "      101     104     105  ...    zooming     zooms     zorro    zorros  \\\n",
       "0 -8.2943 -8.2943 -8.2943  ... -11.512925 -7.601152 -7.601152 -7.601152   \n",
       "\n",
       "    zowie    zucker    zweibel     zwick  zzzzzzzzz       Y  \n",
       "0 -8.2943 -7.601152 -11.512925 -7.601152 -11.512925  0.5178  \n",
       "\n",
       "[1 rows x 20585 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fresh_wordprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words_fresh_count dictionary has all probability of every word given the word appeared in a fresh review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['000', '0014', '007', '044', '07', '10', '100', '101', '104', '105',\n",
       "       ...\n",
       "       'zooming', 'zooms', 'zorro', 'zorros', 'zowie', 'zucker', 'zweibel',\n",
       "       'zwick', 'zzzzzzzzz', 'Y'],\n",
       "      dtype='object', length=20585)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_rotten = train_rotten.columns\n",
    "columns_rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_rotten_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the log likelihood for word given rotten. We assign 10e-5 for all words that have count 0.\n",
    "for col in columns_rotten:\n",
    "    count = train_rotten[col].sum()\n",
    "    if count == 0:\n",
    "        words_rotten_count[col] = np.log(0.00001)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        words_rotten_count[col] = np.log(count/ train_rotten.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words_rotten_count dictionary has all probability of every word given the word appeared in a rotten review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rotten_wordprob = pd.DataFrame(words_rotten_count, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-5.809393</td>\n",
       "      <td>-6.684862</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000       0014       007        044         07        10       100  \\\n",
       "0 -8.2943 -11.512925 -7.601152 -11.512925 -11.512925 -5.809393 -6.684862   \n",
       "\n",
       "         101        104        105  ...  zooming      zooms     zorro  \\\n",
       "0 -11.512925 -11.512925 -11.512925  ...  -8.2943 -11.512925 -7.601152   \n",
       "\n",
       "      zorros      zowie  zucker    zweibel   zwick  zzzzzzzzz          Y  \n",
       "0 -11.512925 -11.512925 -8.2943 -11.512925 -8.2943 -11.512925 -11.512925  \n",
       "\n",
       "[1 rows x 20585 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rotten_wordprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q2.6- For both destination classes, F and R, compute the log-likelihood that the quote belongs to this class.\n",
    "log-likelihood is what is given inside the brackets in equation (1) on slide 28, and the equations on\n",
    "Schutt \u0010Doing Data Science\u0011, page 102. In lecture notes it is explained before the email classi\u001c",
    "cation\n",
    "example (and in the example too). On the slides we have the log-likelihood essentially as (although\n",
    "we do not write it out):***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got the Pr(word/ fresh) from the words_fresh_count dictionary for every word.\n",
    "\n",
    "We have got the Pr(word/ fresh) from the words_rotten_count dictionary for every word.\n",
    "\n",
    "We would use these probabilities on the test set to check if the quote is fresh or rotten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are making a copy of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last column of test_df, df_fresh_wordprob, df_rotten_wordprob is Y, we do not need this column for calculating log liklihoods. So we would get rid of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_withoutY = test_df[test_df.columns.difference(['Y'])]\n",
    "df_fresh_wordprob_withoutY = df_fresh_wordprob[df_fresh_wordprob.columns.difference(['Y'])]\n",
    "df_rotten_wordprob_withoutY = df_rotten_wordprob[df_rotten_wordprob.columns.difference(['Y'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2680, 20584)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_withoutY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20584)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_fresh_wordprob_withoutY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would add another columns for the liklihood of each quote being fresh or rotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get a series for every quote's log liklihood of being fresh\n",
    "\n",
    "fresh_liklihood = test_df_withoutY @ df_fresh_wordprob_withoutY.transpose() + log_Pr_fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get a series for every quote's log liklihood of being rotten\n",
    "\n",
    "rotten_liklihood= test_df_withoutY @ df_rotten_wordprob_withoutY.transpose() + log_Pr_rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['fresh_liklihood'] = fresh_liklihood #We add a column for every quote's log liklihood of being fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['rotten_liklihood'] = rotten_liklihood #We add a column for every quote's log liklihood of being rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We make a prediction column based on liklihood of being fresh or rotten\n",
    "\n",
    "test_df['prediction'] = np.where(test_df['fresh_liklihood'] >= test_df['rotten_liklihood'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>Y</th>\n",
       "      <th>fresh_liklihood</th>\n",
       "      <th>rotten_liklihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.156332</td>\n",
       "      <td>-45.798893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-91.461301</td>\n",
       "      <td>-94.663536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-16.168146</td>\n",
       "      <td>-21.971471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-87.891281</td>\n",
       "      <td>-91.913357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-32.760565</td>\n",
       "      <td>-36.053072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20587 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       000  0014  007  044  07  10  100  101  104  105  ...  zorro  zorros  \\\n",
       "13126    0     0    0    0   0   0    0    0    0    0  ...      0       0   \n",
       "978      0     0    0    0   0   0    0    0    0    0  ...      0       0   \n",
       "10904    0     0    0    0   0   0    0    0    0    0  ...      0       0   \n",
       "11621    0     0    0    0   0   0    0    0    0    0  ...      0       0   \n",
       "2807     0     0    0    0   0   0    0    0    0    0  ...      0       0   \n",
       "\n",
       "       zowie  zucker  zweibel  zwick  zzzzzzzzz    Y  fresh_liklihood  \\\n",
       "13126      0       0        0      0          0  0.0       -40.156332   \n",
       "978        0       0        0      0          0  1.0       -91.461301   \n",
       "10904      0       0        0      0          0  1.0       -16.168146   \n",
       "11621      0       0        0      0          0  0.0       -87.891281   \n",
       "2807       0       0        0      0          0  1.0       -32.760565   \n",
       "\n",
       "       rotten_liklihood  \n",
       "13126        -45.798893  \n",
       "978          -94.663536  \n",
       "10904        -21.971471  \n",
       "11621        -91.913357  \n",
       "2807         -36.053072  \n",
       "\n",
       "[5 rows x 20587 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.prediction.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q2.7 Print the resulting confusion matrix and accuracy (feel free to use existing libraries).***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would make a copy of the data frame test_df; because we have to change data types on Y and prediction columns to print confusion matrix. Currently one is int and the other is float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1664\n",
       "0.0    1016\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1.Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2546\n",
       "0     134\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1.prediction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.Y = test_df1.Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1664\n",
       "0    1016\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2546\n",
       "0     134\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1592</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>954</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1\n",
       "0  1592  72\n",
       "1   954  62"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the confusion matrix\n",
    "c = pd.DataFrame(sklearn.metrics.confusion_matrix(test_df.Y, test_df.prediction, labels = [1,0]))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171641791044776"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating accuracy\n",
    "accuracy = (c[0][0] + c[1][1])/ (c[0][0] + c[1][1] + c[0][1]+c[1][0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3- Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.1- Extract from your conditional probability vectors log Pr(w|F) and log Pr(w|R) the probabilities that\n",
    "correspond to frequent words only.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-6.908005</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-6.684862</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-5.403928</td>\n",
       "      <td>-6.348389</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.5178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000       0014       007        044         07        10       100  \\\n",
       "0 -6.908005 -11.512925 -6.684862 -11.512925 -11.512925 -5.403928 -6.348389   \n",
       "\n",
       "      101     104     105  ...    zooming     zooms     zorro    zorros  \\\n",
       "0 -8.2943 -8.2943 -8.2943  ... -11.512925 -7.601152 -7.601152 -7.601152   \n",
       "\n",
       "    zowie    zucker    zweibel     zwick  zzzzzzzzz       Y  \n",
       "0 -8.2943 -7.601152 -11.512925 -7.601152 -11.512925  0.5178  \n",
       "\n",
       "[1 rows x 20585 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fresh_wordprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The df_fresh_wordprob has the log(Pr(word|fresh)) for every word. We would make its copy and sort in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequent_words_fresh = df_fresh_wordprob.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-6.908005</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-6.684862</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-5.403928</td>\n",
       "      <td>-6.348389</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-8.2943</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-7.601152</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>0.5178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000       0014       007        044         07        10       100  \\\n",
       "0 -6.908005 -11.512925 -6.684862 -11.512925 -11.512925 -5.403928 -6.348389   \n",
       "\n",
       "      101     104     105  ...    zooming     zooms     zorro    zorros  \\\n",
       "0 -8.2943 -8.2943 -8.2943  ... -11.512925 -7.601152 -7.601152 -7.601152   \n",
       "\n",
       "    zowie    zucker    zweibel     zwick  zzzzzzzzz       Y  \n",
       "0 -8.2943 -7.601152 -11.512925 -7.601152 -11.512925  0.5178  \n",
       "\n",
       "[1 rows x 20585 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frequent_words_fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_words_frequent = df_frequent_words_fresh.sort_values(by = 0,axis=1,ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>film</th>\n",
       "      <th>movie</th>\n",
       "      <th>like</th>\n",
       "      <th>story</th>\n",
       "      <th>good</th>\n",
       "      <th>best</th>\n",
       "      <th>time</th>\n",
       "      <th>comedy</th>\n",
       "      <th>just</th>\n",
       "      <th>...</th>\n",
       "      <th>antipollution</th>\n",
       "      <th>singers</th>\n",
       "      <th>antiquated</th>\n",
       "      <th>persuasions</th>\n",
       "      <th>gaggle</th>\n",
       "      <th>sinewy</th>\n",
       "      <th>sinecures</th>\n",
       "      <th>persuasiveness</th>\n",
       "      <th>sin</th>\n",
       "      <th>sh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>-1.374616</td>\n",
       "      <td>-1.475376</td>\n",
       "      <td>-2.380797</td>\n",
       "      <td>-2.510474</td>\n",
       "      <td>-2.551296</td>\n",
       "      <td>-2.753036</td>\n",
       "      <td>-2.822029</td>\n",
       "      <td>-2.834714</td>\n",
       "      <td>-2.843261</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "      <td>-11.512925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y      film     movie      like     story      good      best  \\\n",
       "0  0.5178 -1.374616 -1.475376 -2.380797 -2.510474 -2.551296 -2.753036   \n",
       "\n",
       "       time    comedy      just  ...  antipollution    singers  antiquated  \\\n",
       "0 -2.822029 -2.834714 -2.843261  ...     -11.512925 -11.512925  -11.512925   \n",
       "\n",
       "   persuasions     gaggle     sinewy  sinecures  persuasiveness        sin  \\\n",
       "0   -11.512925 -11.512925 -11.512925 -11.512925      -11.512925 -11.512925   \n",
       "\n",
       "          sh  \n",
       "0 -11.512925  \n",
       "\n",
       "[1 rows x 20585 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_words_frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Y', 'film', 'movie', 'like', 'story', 'good', 'best', 'time', 'comedy',\n",
       "       'just', 'director'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_words_frequent.columns[0:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 most frequent words in the movies reviewed as fresh are: \n",
    "\n",
    "'film', 'movie', 'like', 'story', 'good', 'best', 'just','director', 'comedy','time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The df_rotten_wordprob has the log(Pr(word/ rotten)) for every word. We would make its copy and sort in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['film', 'movie', 'like', 'comedy', 'good', 'story', 'director', 'time',\n",
       "       'movies', 'just'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_frequent_words_rotten = df_rotten_wordprob.copy()\n",
    "rotten_words_frequent = df_frequent_words_rotten.sort_values(by = 0,axis=1,ascending = False)\n",
    "rotten_words_frequent.columns[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 most frequent words in the movies reviewed as rotten are: \n",
    "\n",
    "'film', 'movie', 'like', 'comedy', 'good', 'story', 'time', 'director', 'funny', 'make'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.1- Extract from your conditional probability vectors log Pr(w|F) and log Pr(w|R) the probabilities that\n",
    "correspond to frequent words only.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would consider those words who appeared at leaset 30 times in the fresh reviews; and those words which appeared more than 30 times in the rotten reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would calculate the log of 30/total number of rows; and find the words whose log liklihood are grtaer than this for fresh and rotten seprately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = log(30/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.492374691842747"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_fresh_morethan30 = {} #creating an empty dictionary to store the frequent words and theirlog liklihoods from fresh reviews.\n",
    "for col in df_fresh_wordprob.columns:\n",
    "    if df_fresh_wordprob[col][0] >= threshold:\n",
    "        words_fresh_morethan30[col] = df_fresh_wordprob[col][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_fresh_morethan30 = pd.DataFrame(words_fresh_morethan30, index = [0]) #converting dictionary to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_rotten_morethan30 = {} #creating an empty dictionary to store the frequent words and theirlog liklihoods from rotten reviews.\n",
    "for col in df_rotten_wordprob.columns:\n",
    "    if df_rotten_wordprob[col][0] >= threshold:\n",
    "        words_rotten_morethan30[col] = df_rotten_wordprob[col][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_rotten_morethan30 = pd.DataFrame(words_rotten_morethan30, index = [0]) #converting dictionary to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q3.2 Find 10 best words to predict F and 10 best words to predict R. Hint: imagine we have a review that\n",
    "contains just a single word. Which word will give the highest weight to the probability the review is\n",
    "fresh? Which one to the likelihood it is rotten?\n",
    "Comment your results.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_fresh_morethan30 = df_words_fresh_morethan30.sort_values(by = 0,axis=1,ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Y', 'film', 'movie', 'like', 'story', 'good', 'best', 'time', 'comedy',\n",
       "       'just'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words_fresh_morethan30.columns[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_rotten_morethan30 = df_words_rotten_morethan30.sort_values(by = 0,axis=1,ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['film', 'movie', 'like', 'comedy', 'good', 'story', 'director', 'time',\n",
       "       'movies', 'just'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words_rotten_morethan30.columns[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the log probabilities of the word given it is in fresh and rotten reviews respectively.  Then we took the difference of log probabilities of the same word occuring in fresh and rotten reviews. If the difference is positive then it means the word is a good predictor that the review is fresh. If the difference is negative then we conclude that the word is a good predictor of a rotten review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = df_fresh_wordprob - df_rotten_wordprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0014</th>\n",
       "      <th>007</th>\n",
       "      <th>044</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zorros</th>\n",
       "      <th>zowie</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zzzzzzzzz</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.336472</td>\n",
       "      <td>3.218626</td>\n",
       "      <td>3.218626</td>\n",
       "      <td>3.218626</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.218626</td>\n",
       "      <td>3.911773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.911773</td>\n",
       "      <td>3.218626</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.030725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000  0014       007  044   07        10       100       101       104  \\\n",
       "0  1.386294   0.0  0.916291  0.0  0.0  0.405465  0.336472  3.218626  3.218626   \n",
       "\n",
       "        105  ...   zooming     zooms  zorro    zorros     zowie    zucker  \\\n",
       "0  3.218626  ... -3.218626  3.911773    0.0  3.911773  3.218626  0.693147   \n",
       "\n",
       "   zweibel     zwick  zzzzzzzzz          Y  \n",
       "0      0.0  0.693147        0.0  12.030725  \n",
       "\n",
       "[1 rows x 20585 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_descending = difference.sort_values(by = 0,axis=1,ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>capra</th>\n",
       "      <th>sturges</th>\n",
       "      <th>scare</th>\n",
       "      <th>balanced</th>\n",
       "      <th>confused</th>\n",
       "      <th>preston</th>\n",
       "      <th>convoluted</th>\n",
       "      <th>mendes</th>\n",
       "      <th>destined</th>\n",
       "      <th>...</th>\n",
       "      <th>segments</th>\n",
       "      <th>lie</th>\n",
       "      <th>wives</th>\n",
       "      <th>wayans</th>\n",
       "      <th>bertino</th>\n",
       "      <th>mcadams</th>\n",
       "      <th>dangerfield</th>\n",
       "      <th>bana</th>\n",
       "      <th>georgia</th>\n",
       "      <th>excruciating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.030725</td>\n",
       "      <td>5.857683</td>\n",
       "      <td>5.703533</td>\n",
       "      <td>5.703533</td>\n",
       "      <td>5.703533</td>\n",
       "      <td>5.616521</td>\n",
       "      <td>5.41585</td>\n",
       "      <td>5.41585</td>\n",
       "      <td>5.298067</td>\n",
       "      <td>5.298067</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.828064</td>\n",
       "      <td>-4.828064</td>\n",
       "      <td>-4.828064</td>\n",
       "      <td>-4.828064</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Y     capra   sturges     scare  balanced  confused  preston  \\\n",
       "0  12.030725  5.857683  5.703533  5.703533  5.703533  5.616521  5.41585   \n",
       "\n",
       "   convoluted    mendes  destined  ...  segments       lie     wives  \\\n",
       "0     5.41585  5.298067  5.298067  ... -4.828064 -4.828064 -4.828064   \n",
       "\n",
       "     wayans   bertino   mcadams  dangerfield      bana   georgia  excruciating  \n",
       "0 -4.828064 -5.010385 -5.010385    -5.010385 -5.010385 -5.010385     -5.010385  \n",
       "\n",
       "[1 rows x 20585 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Y', 'capra', 'sturges', 'scare', 'balanced', 'confused', 'preston',\n",
       "       'convoluted', 'mendes', 'destined'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_descending.columns[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have words like nostalgic, confused, balanced and craftsmanship that occur the most as good indicators of fresh review. Kindly ignore Y which is a target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_ascending = difference.sort_values(by = 0,axis=1,ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dangerfield</th>\n",
       "      <th>bana</th>\n",
       "      <th>georgia</th>\n",
       "      <th>excruciating</th>\n",
       "      <th>bertino</th>\n",
       "      <th>mcadams</th>\n",
       "      <th>wayans</th>\n",
       "      <th>lie</th>\n",
       "      <th>pile</th>\n",
       "      <th>segments</th>\n",
       "      <th>...</th>\n",
       "      <th>heads</th>\n",
       "      <th>freudian</th>\n",
       "      <th>convoluted</th>\n",
       "      <th>preston</th>\n",
       "      <th>confused</th>\n",
       "      <th>scare</th>\n",
       "      <th>sturges</th>\n",
       "      <th>balanced</th>\n",
       "      <th>capra</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-5.010385</td>\n",
       "      <td>-4.828064</td>\n",
       "      <td>-4.828064</td>\n",
       "      <td>-4.828064</td>\n",
       "      <td>-4.828064</td>\n",
       "      <td>...</td>\n",
       "      <td>5.298067</td>\n",
       "      <td>5.298067</td>\n",
       "      <td>5.41585</td>\n",
       "      <td>5.41585</td>\n",
       "      <td>5.616521</td>\n",
       "      <td>5.703533</td>\n",
       "      <td>5.703533</td>\n",
       "      <td>5.703533</td>\n",
       "      <td>5.857683</td>\n",
       "      <td>12.030725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dangerfield      bana   georgia  excruciating   bertino   mcadams  \\\n",
       "0    -5.010385 -5.010385 -5.010385     -5.010385 -5.010385 -5.010385   \n",
       "\n",
       "     wayans       lie      pile  segments  ...     heads  freudian  \\\n",
       "0 -4.828064 -4.828064 -4.828064 -4.828064  ...  5.298067  5.298067   \n",
       "\n",
       "   convoluted  preston  confused     scare   sturges  balanced     capra  \\\n",
       "0     5.41585  5.41585  5.616521  5.703533  5.703533  5.703533  5.857683   \n",
       "\n",
       "           Y  \n",
       "0  12.030725  \n",
       "\n",
       "[1 rows x 20585 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dangerfield', 'bana', 'georgia', 'excruciating', 'bertino', 'mcadams',\n",
       "       'wayans', 'lie', 'pile', 'segments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_ascending.columns[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have words like shocker, burns, dangerfield that occur the most as good indicators of rotten review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***3.3  Print out a few missclassified quotes. Can you understand why these are misclassified?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the quotes which are misclassified as rotten instead of fresh and store in list Quote_labelFtoR\n",
    "Quote_labelFtoR = test_df1[test_df1['Y']>test_df1['prediction']].index.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Quote_labelFtoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6339, 4959, 10337, 9891, 12657]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some sample indices we got above\n",
    "Quote_labelFtoR[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the quotes which are misclassified as fresh instead of rotten and store in list Quote_labelRtoF\n",
    "Quote_labelRtoF = test_df1[test_df1['Y']<test_df1['prediction']].index.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfred Hitchcock's first indisputable masterpiece.\n",
      "Made with fluid skill and a passion for storytelling, its tale of how the Vietnam War and American society affect a black Marine remains accessible while confounding expectations.\n",
      "There are no laughs to be found in writer-director Michael Traeger's would-be comedy The Amateurs, but there is one big mystery: how actors of this caliber could have been convinced to take part.\n",
      "This setup isn't exactly what you'd call plausible, but the follow-through is consistent and clever.\n",
      "Coppola adapted the novel himself, and he's done a good job of paring it down.\n"
     ]
    }
   ],
   "source": [
    "#This loop is used to print 5 quotes that are misclassified from rotten to fresh.\n",
    "for index in Quote_labelRtoF[20:25]:\n",
    "    print(cleaned_df.quote.values[index])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A likable but wan romance.\n",
      "Besson fatally misjudges the cinematic interest of his theme.\n",
      "You sometimes have to giggle at this movie the way you do when you catch 4-year-olds playing dress-up in front of Mom's closet.\n",
      "Those in sore need of busting a gut had better look elsewhere for comic relief.\n",
      "There is beauty in Kagemusha but it is impersonal, distant and ghostly. The old master has never been more rigorous.\n"
     ]
    }
   ],
   "source": [
    "#This loop is used to print 5 quotes that are misclassified from fresh to rotten.\n",
    "for index in Quote_labelFtoR[0:5]:\n",
    "    print(cleaned_df.quote.values[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets take one sentence from above i.e \"A movie so in love with itself it hardly needs us at all.\" The overall tone of this review is negative by taking all words together and understanding the context of the review quote. However if we see the individual log probabilities of these words when taken independently weighs more in favor of a fresh review hence our model has classified as fresh instead of rotten.We will demonstrate this below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = \"A movie so in love with itself it hardly needs us at all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_words = quote.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_prob_infresh = {}\n",
    "for word in quote_words:\n",
    "    if word in df_fresh_wordprob.columns:\n",
    "        words_prob_infresh[word]=df_fresh_wordprob[word][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': -1.4753755435817137,\n",
       " 'love': -3.5669117901448946,\n",
       " 'hardly': -5.40392785096107,\n",
       " 'needs': -5.158805392928086}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_prob_infresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_prob_inrotten = {}\n",
    "for word in quote_words:\n",
    "    if word in df_rotten_wordprob.columns:\n",
    "        words_prob_inrotten[word]=df_rotten_wordprob[word][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': -2.004584037948238,\n",
       " 'love': -4.119912338961598,\n",
       " 'hardly': -5.896404336058865,\n",
       " 'needs': -5.461086264801019}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_prob_inrotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So as we can see for the words in example sentence have higher log probability for fresh when compared to rotten. As a result of which our model classifies this quote/review as fresh instead of rotten as we see through human eyes when taken together in the context instead of independent word log probabilities.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pr(word/fresh) is higher than Pr(word/rotten) for each of these words in the quote. That is why we feel our model misclassified this quote as fresh although it should actually be rotten review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4- NB with smoothing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q4.1 and Q4.2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(train, alpha): #train= training data, alpha = smoothehing parameter\n",
    "    \n",
    "    number_fresh = pd.DataFrame(train.Y.value_counts())['Y'][1] #the fresh reviews have Y =1\n",
    "    number_rotten = pd.DataFrame(train.Y.value_counts())['Y'][0] #the rotten reviews have Y = 0\n",
    "    total = number_fresh + number_rotten\n",
    "    \n",
    "    Pr_fresh = number_fresh/total #finding probability of a review being fresh\n",
    "    Pr_rotten = number_rotten/total #finding probability of a review being rotten\n",
    "    \n",
    "    log_Pr_fresh = np.log(Pr_fresh)\n",
    "    log_Pr_rotten = np.log(Pr_rotten)\n",
    "    \n",
    "    train_fresh = train[train['Y'] == 1] #subsetting the data for Y =1\n",
    "    train_rotten = train[train['Y'] == 0] #subsetting the data for Y =0\n",
    "    \n",
    "    #finding log(Pr(word/ fresh)) for every word\n",
    "    columns_fresh = train_fresh.columns\n",
    "    words_fresh_count = {}\n",
    "    \n",
    "    for col in columns_fresh:\n",
    "        \n",
    "        count = train_fresh[col].sum()\n",
    "        words_fresh_count[col] = np.log((count+alpha)/ (train_rotten.shape[0]+alpha)) \n",
    "        \n",
    "    df_fresh_wordprob = pd.DataFrame(words_fresh_count, index = [0])\n",
    "        \n",
    "    #finding log(Pr(word/ rotten)) for every word\n",
    "    columns_rotten = train_rotten.columns\n",
    "    words_rotten_count = {}\n",
    "    \n",
    "    for col in columns_rotten:\n",
    "        \n",
    "        count = train_rotten[col].sum()\n",
    "        words_rotten_count[col] = np.log((count+alpha)/ (train_rotten.shape[0]+alpha)) #We are adding alpha in numerator and denominator for smoothening\n",
    "        \n",
    "    df_rotten_wordprob = pd.DataFrame(words_rotten_count, index = [0])\n",
    "    \n",
    "    return log_Pr_fresh, log_Pr_rotten, df_fresh_wordprob, df_rotten_wordprob\n",
    "    \n",
    "#We are returning 4 things: 1.the probability of a quote being fresh, 2.the probability of a quote being fresh,\n",
    "# 3.the data frame having words as column; and a single row having log(Pr(Word/ fresh)) for each word,\n",
    "# 4.the data frame having words as column; and a single row having log(Pr(Word/ rotten)) for each word,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Pr_fresh, log_Pr_rotten, df_fresh_wordprob, df_rotten_wordprob = model_fit(train, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that we are passing the trst data set and not the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(log_Pr_fresh, log_Pr_rotten, df_fresh_wordprob, df_rotten_wordprob, test): #test means the validation dataset\n",
    "    \n",
    "    test_df = test.copy()\n",
    "    \n",
    "    #The last column of test_df, df_fresh_wordprob, df_rotten_wordprob is Y, we do not need this column for calculating log liklihoods. \n",
    "    #So we would get rid of this Y column.\n",
    "    \n",
    "    test_df_withoutY = test_df[test_df.columns.difference(['Y'])]\n",
    "    df_fresh_wordprob_withoutY = df_fresh_wordprob[df_fresh_wordprob.columns.difference(['Y'])]\n",
    "    df_rotten_wordprob_withoutY = df_rotten_wordprob[df_rotten_wordprob.columns.difference(['Y'])]\n",
    "    \n",
    "    #doing matrix multiplications\n",
    "    fresh_liklihood = test_df_withoutY @ df_fresh_wordprob_withoutY.transpose() + log_Pr_fresh\n",
    "    rotten_liklihood= test_df_withoutY @ df_rotten_wordprob_withoutY.transpose() + log_Pr_rotten\n",
    "    \n",
    "    test_df['fresh_liklihood'] = fresh_liklihood #We add a column for every quote's log liklihood of being fresh\n",
    "    test_df['rotten_liklihood'] = rotten_liklihood #We add a column for every quote's log liklihood of being rotten\n",
    "    \n",
    "    #We make a prediction column based on liklihood of being fresh or rotten\n",
    "    test_df['prediction'] = np.where(test_df['fresh_liklihood'] >= test_df['rotten_liklihood'], 1, 0)\n",
    "    \n",
    "    #creating confusion matrix\n",
    "    c = pd.DataFrame(sklearn.metrics.confusion_matrix(test_df.Y, test_df.prediction, labels = [1,0]))\n",
    "    accuracy = (c[0][0] + c[1][1])/ (c[0][0] + c[1][1] + c[0][1]+c[1][0])\n",
    "    \n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6179104477611941"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = model_predict(log_Pr_fresh, log_Pr_rotten, df_fresh_wordprob, df_rotten_wordprob, test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Q4.3- Cross-validate the accuracy (on the validation data) on a number of \u000b",
    " values and \u001c",
    "nd the \u000b",
    " that\n",
    "gives you the best result. You can use your own CV algorithm you created for PS4, or an existing\n",
    "library.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XY_BOW_df1 is our cleaned data set. We would be using this for k fold cross validation. \n",
    "\n",
    "We want to run for different alpha values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    kfold = KFold(n_splits=5, random_state=100, shuffle=False) #writing code for k fold\n",
    "\n",
    "    def cross_validate(XY_BOW_df1):\n",
    "        alpha_list = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "        \n",
    "\n",
    "        for alpha in alpha_list:\n",
    "            accuracy_list = []\n",
    "            for train_index, test_index  in kfold.split(XY_BOW_df1): #get train and test indices for k fold cross validation\n",
    "                train, test = XY_BOW_df1.iloc[train_index], XY_BOW_df1.iloc[test_index]\n",
    "\n",
    "                \n",
    "                log_Pr_fresh, log_Pr_rotten, df_fresh_wordprob, df_rotten_wordprob = model_fit(train, alpha)\n",
    "\n",
    "                accuracy = model_predict(log_Pr_fresh, log_Pr_rotten, df_fresh_wordprob, df_rotten_wordprob, test)\n",
    "                \n",
    "                accuracy_list.append(accuracy)\n",
    "            avg_accuracy = sum(accuracy_list)/len(accuracy_list)\n",
    "\n",
    "            print(\"The alpha is {} and the average accuracy is {}\".format(alpha, avg_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alpha is 0.1 and the average accuracy is 0.6157094148518327\n",
      "The alpha is 0.2 and the average accuracy is 0.6172771361557274\n",
      "The alpha is 0.3 and the average accuracy is 0.6189941669034448\n",
      "The alpha is 0.4 and the average accuracy is 0.6204871220604703\n",
      "The alpha is 0.5 and the average accuracy is 0.6213829787234043\n",
      "The alpha is 0.6 and the average accuracy is 0.6216068036079401\n",
      "The alpha is 0.7 and the average accuracy is 0.6228758503117113\n",
      "The alpha is 0.8 and the average accuracy is 0.6232491796337463\n",
      "The alpha is 0.9 and the average accuracy is 0.6236224532433019\n"
     ]
    }
   ],
   "source": [
    "cross_validate(XY_BOW_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I was running the cross validation, the highest accuracy was for alpha = 0.9, and the accuracy was 62.3%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
